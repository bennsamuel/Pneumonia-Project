{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Group_77-Pneumonia.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bennsamuel/Pneumonia-Project/blob/master/cnn_parameter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1HJrduozTKM",
        "colab_type": "text"
      },
      "source": [
        "# Deletes log folder\n",
        "should not be used. Was implemented when cnn algorithm was not finshed to mingle around.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uukp28eezLbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# %cd /content/drive/My Drive/Group 77 - Pneumonia/logs\n",
        "# !rm -d -r *\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khtTZm2LqT9b",
        "colab_type": "text"
      },
      "source": [
        "# START HERE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gCSpATnMr5e",
        "colab_type": "code",
        "outputId": "6505057e-2663-4ab1-bd3b-0228715cfaf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# START HERE\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4AOCheJNu3U",
        "colab_type": "code",
        "outputId": "65371a56-0c51-44f9-e9aa-88ee717cc970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/drive/My Drive/Group 77 - Pneumonia/pickle/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_data.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peGASGqf1tHI",
        "colab_type": "code",
        "outputId": "f0d0e328-c8df-49d9-b4db-a566307f3704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "IMG_SIZE = 224\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "#                0          1         2\n",
        "CATEGORIES = [\"NORMAL\",\"BACTERIA\", \"VIRUS\"]\n",
        "\n",
        "\n",
        "%cd /content/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G534nMYhAJEY",
        "colab_type": "text"
      },
      "source": [
        "## `DATA SET which should be used for training is defined here.`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wHYgnMIKEPlo",
        "colab_type": "code",
        "outputId": "4cb41671-9dd4-4264-9c96-3457b887d7a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#load dataset --> method baseline!\n",
        "import pickle\n",
        "\n",
        "# select which pickle folder\n",
        "\n",
        "# HERE Define here which data set should be used for training\n",
        "\n",
        "data_set_path = \"/content/drive/My Drive/Group 77 - Pneumonia/pickle/test_data.pickle\"\n",
        "# extract name from dataset\n",
        "specific_data_set = data_set_path.split('/')[-1]\n",
        "\n",
        "# train set\n",
        "data = pickle.load(open(data_set_path, \"rb\"))\n",
        "\n",
        "# validation set\n",
        "test_data = pickle.load(open(\"/content/drive/My Drive/Group 77 - Pneumonia/pickle/test_data.pickle\", \"rb\"))\n",
        "\n",
        "print(\"Mounted data set: {}\".format(specific_data_set))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted data set: test_data.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdZyLUR16qn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CZybEQwoEPlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# splitting data in training data and validation data \n",
        "# creating normalized SHUFFLED arrays\n",
        "# DUE TO REFACTORING validaiton set it called test set\n",
        "import numpy as np\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for features, label in data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "    \n",
        "X_train = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y_train = y\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for features, label in test_data:\n",
        "    X_test.append(features)\n",
        "    y_test.append(label)\n",
        "    \n",
        "X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O9_iDu0sEPls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.asarray(X_train)\n",
        "y_train = np.asarray(y_train)\n",
        "\n",
        "# X_val = np.asarray(X_val)\n",
        "# y_val = np.asarray(y_val)\n",
        "\n",
        "X_test = np.asarray(X_test)\n",
        "y_test = np.asarray(y_test)\n",
        "\n",
        "X_train = X_train/255.0\n",
        "# X_val = X_val/255.0\n",
        "X_test = X_test/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i1TriNTImBb",
        "colab_type": "text"
      },
      "source": [
        "'one hot encode' classes\n",
        "\n",
        "before to_categorical: \n",
        "\n",
        "  [1, \n",
        "  2,\n",
        "  1, \n",
        "  0, \n",
        "  1, \n",
        "  2, \n",
        "  ...]\n",
        "\n",
        "after to_categorical:\n",
        "  [[0,1,0],\n",
        "   [0,0,1],\n",
        "   [0,1,0],\n",
        "   ...]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tGqdvi4Im3Q",
        "colab_type": "code",
        "outputId": "e21daea8-9069-473d-9e2f-41653862e94c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4aeHNCs4Pi6",
        "colab_type": "code",
        "outputId": "c3af31d3-c316-4b74-dab5-a1228e1e9010",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(624, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhZc6GMNurYi",
        "colab_type": "text"
      },
      "source": [
        "Defining layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1scT1xVPDyN2",
        "colab_type": "text"
      },
      "source": [
        "Code partially based on [stanford cs 231](http://cs231n.github.io/convolutional-networks/)\n",
        "\n",
        "**strides and dropout** \n",
        "\n",
        "Decided to use increased strides instead of maxpooling layer. Based on:\n",
        "https://www.kaggle.com/dansbecker/dropout-and-strides-for-larger-models\n",
        "\n",
        "and corresponding research paper:\n",
        "[\"Striving for Simplicity: The All Convolutional Net\"](https://academic.microsoft.com/paper/2963382180/citedby/search?q=Striving%20for%20Simplicity%3A%20The%20All%20Convolutional%20Net&qe=RId%253D2963382180&f=&orderBy=0)\n",
        "\n",
        "Dropout percentage (0.5) based on [this paper](https://academic.microsoft.com/paper/1904365287/reference/search?q=Improving%20neural%20networks%20by%20preventing%20co-adaptation%20of%20feature%20detectors&qe=Or(Id%253D2911964244%252CId%253D2108598243%252CId%253D2112796928%252CId%253D2100495367%252CId%253D2912934387%252CId%253D2116064496%252CId%253D2147768505%252CId%253D1993882792%252CId%253D4919037%252CId%253D1498436455%252CId%253D2053229256%252CId%253D2132424367%252CId%253D2184852195%252CId%253D1567512734%252CId%253D2150884987%252CId%253D2125725328%252CId%253D2465562739)&f=&orderBy=0)\n",
        "\n",
        "[another paper](http://jmlr.csail.mit.edu/papers/volume15/srivastava14a/srivastava14a.pdf) on dropout cited by google\n",
        "\n",
        "Why dropout is not used on convolutional layer:\n",
        "[link text](https://academic.microsoft.com/paper/2890166761/citedby/search?q=DropBlock%3A%20A%20regularization%20method%20for%20convolutional%20networks&qe=RId%253D2890166761&f=&orderBy=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Q-5ThfjpEPlv",
        "colab_type": "code",
        "outputId": "2d68f671-0686-408d-d698-4203376bec25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "import time\n",
        "\n",
        "NAME = \"{data_set} - {time}\".format(data_set = specific_data_set, time = time.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
        "\n",
        "tensorboard = TensorBoard(log_dir = \"/content/drive/My Drive/Group 77 - Pneumonia/logs/{}\".format(NAME))\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3),\n",
        "                 strides=2,\n",
        "                 activation='relu',\n",
        "                 input_shape=X_train.shape[1:]))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), strides=2, activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), strides=2, activation='relu'))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), strides=2, activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), strides=2, activation='relu'))\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), strides=2, activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# w/o regularization\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# with regularization\n",
        "model.add(Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.1)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.1)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Dense 3 softmax because we have 3 classes\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYCGbces_grt",
        "colab_type": "text"
      },
      "source": [
        "Fitting the model. If this is executed multiple times make sure that no addiotional layers were added by runnning the cell above. *THIS DOES NOT WORK. YOU HAVE TO RESTART THE RUNTIME* This can be checked with the model.layers variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgWk5UAyA2cJ",
        "colab_type": "code",
        "outputId": "27b30f33-1aae-4813-81cf-9974e5794dd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Mounted data set: {}\".format(specific_data_set))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted data set: test_data.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yoexBRn0yEP",
        "colab_type": "code",
        "outputId": "47b6bc4f-f940-4f51-bfb9-139498e4517d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fc579beae48>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fc579bf1278>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fc579bf1208>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fc579bf1be0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fc579367c88>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fc57937c2b0>,\n",
              " <tensorflow.python.keras.layers.core.Flatten at 0x7fc57937c278>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7fc579323b70>,\n",
              " <tensorflow.python.keras.layers.core.Dropout at 0x7fc57931c0b8>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7fc579387978>,\n",
              " <tensorflow.python.keras.layers.core.Dropout at 0x7fc579346a90>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7fc57932acc0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHuOkCRt_uO_",
        "colab_type": "code",
        "outputId": "1e562082-bde4-47dc-a3d0-f66f275199cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "precision = tf.keras.metrics.Precision()\n",
        "recall = tf.keras.metrics.Recall()\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", \n",
        "              optimizer=\"adam\", \n",
        "              metrics=[\"accuracy\", precision, recall])\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=30, validation_data=(X_test,y_test), callbacks = [tensorboard])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 624 samples, validate on 624 samples\n",
            "Epoch 1/10\n",
            "128/624 [=====>........................] - ETA: 14s - loss: 36.6372 - acc: 0.3984 - precision: 0.0000e+00 - recall: 0.0000e+00WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.203821). Check your callbacks.\n",
            "624/624 [==============================] - 5s 9ms/sample - loss: 34.3884 - acc: 0.3702 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 31.0159 - val_acc: 0.4087 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/10\n",
            "624/624 [==============================] - 1s 1ms/sample - loss: 29.0655 - acc: 0.4054 - precision: 0.7500 - recall: 0.0048 - val_loss: 26.1574 - val_acc: 0.3942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/10\n",
            "624/624 [==============================] - 1s 1ms/sample - loss: 24.4896 - acc: 0.4167 - precision: 0.3333 - recall: 0.0016 - val_loss: 21.9937 - val_acc: 0.5753 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/10\n",
            "624/624 [==============================] - 1s 1ms/sample - loss: 20.5717 - acc: 0.4135 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 18.4647 - val_acc: 0.4487 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/10\n",
            "624/624 [==============================] - 1s 1ms/sample - loss: 17.2746 - acc: 0.4151 - precision: 0.4000 - recall: 0.0032 - val_loss: 15.5022 - val_acc: 0.4183 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/10\n",
            "624/624 [==============================] - 1s 1ms/sample - loss: 14.5030 - acc: 0.5048 - precision: 0.6111 - recall: 0.0353 - val_loss: 13.0192 - val_acc: 0.5160 - val_precision: 1.0000 - val_recall: 0.0080\n",
            "Epoch 7/10\n",
            "624/624 [==============================] - 1s 1ms/sample - loss: 12.2056 - acc: 0.5096 - precision: 0.7111 - recall: 0.1026 - val_loss: 10.8989 - val_acc: 0.6715 - val_precision: 0.9293 - val_recall: 0.2949\n",
            "Epoch 8/10\n",
            "624/624 [==============================] - 1s 1ms/sample - loss: 10.1985 - acc: 0.6122 - precision: 0.7377 - recall: 0.4327 - val_loss: 9.0958 - val_acc: 0.6506 - val_precision: 0.7550 - val_recall: 0.5481\n",
            "Epoch 9/10\n",
            "624/624 [==============================] - 1s 1ms/sample - loss: 8.6357 - acc: 0.6298 - precision: 0.7394 - recall: 0.4455 - val_loss: 7.7430 - val_acc: 0.6779 - val_precision: 0.7316 - val_recall: 0.5897\n",
            "Epoch 10/10\n",
            "624/624 [==============================] - 1s 1ms/sample - loss: 7.4065 - acc: 0.6587 - precision: 0.7440 - recall: 0.5449 - val_loss: 6.6695 - val_acc: 0.6875 - val_precision: 0.8441 - val_recall: 0.5465\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc579278e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}