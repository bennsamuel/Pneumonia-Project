{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "cnn_parameter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bennsamuel/Pneumonia-Project/blob/master/cnn_parameter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1HJrduozTKM",
        "colab_type": "text"
      },
      "source": [
        "# Deletes log folder\n",
        "should not be used. Was implemented when cnn algorithm was not finshed to mingle around.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uukp28eezLbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# %cd /content/drive/My Drive/Group 77 - Pneumonia/logs\n",
        "# !rm -d -r *\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khtTZm2LqT9b",
        "colab_type": "text"
      },
      "source": [
        "# START HERE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gCSpATnMr5e",
        "colab_type": "code",
        "outputId": "210f2fc3-8f6b-465e-998c-61814ebaf5fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# START HERE\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4AOCheJNu3U",
        "colab_type": "code",
        "outputId": "5e3f05a2-f72d-4e5f-8f43-8047aa47fb6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/drive/My Drive/Group 77 - Pneumonia/pickle/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "old  test_data.pickle  training_data.pickle  validation_data.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peGASGqf1tHI",
        "colab_type": "code",
        "outputId": "8887a444-2f22-49ca-b1b5-fd5eaaff3ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "IMG_SIZE = 224\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "#                0          1         2\n",
        "CATEGORIES = [\"NORMAL\",\"BACTERIA\", \"VIRUS\"]\n",
        "\n",
        "\n",
        "%cd /content/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G534nMYhAJEY",
        "colab_type": "text"
      },
      "source": [
        "## `DATA SET which should be used for training is defined here.`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wHYgnMIKEPlo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "1cb9d00a-83f1-49d9-939a-8caba6915bee"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def parameter_study(data_set_path):\n",
        "\n",
        "    # data_set_path = \"/content/drive/My Drive/Group 77 - Pneumonia/pickle_augmented/aug-{}_{}_{}_{}_{}.pickle\".format(WIDTH_SHIFT,HEIGHT_SHIFT,ZOOM,ROTATION,MIRROR_V)\n",
        "    # extract name from dataset\n",
        "    specific_data_set = data_set_path.split('/')[-1]\n",
        "\n",
        "    # train set\n",
        "    data = pickle.load(open(data_set_path, \"rb\"))\n",
        "\n",
        "    # validation set\n",
        "    test_data = pickle.load(open(\"/content/drive/My Drive/Group 77 - Pneumonia/pickle/validation_data.pickle\", \"rb\"))\n",
        "\n",
        "    print(\"Mounted data set: {}\".format(specific_data_set))\n",
        "\n",
        "    # splitting data in training data and validation data \n",
        "    # creating normalized SHUFFLED arrays\n",
        "    # DUE TO REFACTORING validaiton set it called test set\n",
        "    \n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for features, label in data:\n",
        "        X.append(features)\n",
        "        y.append(label)\n",
        "        \n",
        "    X_train = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    y_train = y\n",
        "\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "\n",
        "    for features, label in test_data:\n",
        "        X_test.append(features)\n",
        "        y_test.append(label)\n",
        "        \n",
        "    X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "\n",
        "    X_train = np.asarray(X_train)\n",
        "    y_train = np.asarray(y_train)\n",
        "\n",
        "    # X_val = np.asarray(X_val)\n",
        "    # y_val = np.asarray(y_val)\n",
        "\n",
        "    X_test = np.asarray(X_test)\n",
        "    y_test = np.asarray(y_test)\n",
        "\n",
        "    X_train = X_train/255.0\n",
        "    # X_val = X_val/255.0\n",
        "    X_test = X_test/255.0\n",
        "\n",
        "\n",
        "\n",
        "    y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "    y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "    y_train.shape\n",
        "\n",
        "    NAME = \"{data_set} - {time}\".format(data_set = specific_data_set, time = time.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
        "\n",
        "    tensorboard = TensorBoard(log_dir = \"/content/drive/My Drive/Group 77 - Pneumonia/logs/{}\".format(NAME))\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3),\n",
        "                    strides=2,\n",
        "                    activation='relu',\n",
        "                    input_shape=X_train.shape[1:]))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), strides=2, activation='relu'))\n",
        "    # model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3), strides=2, activation='relu'))\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3), strides=2, activation='relu'))\n",
        "    # model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(256, kernel_size=(3, 3), strides=2, activation='relu'))\n",
        "    model.add(Conv2D(256, kernel_size=(3, 3), strides=2, activation='relu'))\n",
        "    # model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # w/o regularization\n",
        "    # model.add(Dense(128, activation='relu'))\n",
        "    # model.add(Dropout(0.5))\n",
        "\n",
        "    # model.add(Dense(128, activation='relu'))\n",
        "    # model.add(Dropout(0.5))\n",
        "\n",
        "    # with regularization\n",
        "    model.add(Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.1)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.1)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Dense 3 softmax because we have 3 classes\n",
        "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "    print(\"Mounted data set: {}\".format(specific_data_set))\n",
        "\n",
        "    model.layers\n",
        "\n",
        "    precision = tf.keras.metrics.Precision()\n",
        "    recall = tf.keras.metrics.Recall()\n",
        "\n",
        "    model.compile(loss=\"categorical_crossentropy\", \n",
        "                  optimizer=\"adam\", \n",
        "                  metrics=[\"accuracy\", precision, recall])\n",
        "\n",
        "    model.fit(X_train, y_train, batch_size=128, epochs=30, validation_data=(X_test,y_test), callbacks = [tensorboard])\n",
        "    tf.reset_default_graph()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEBVI45V_tNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f708f274-030f-4ad9-ab5b-46699eca9b17"
      },
      "source": [
        "import os\n",
        "\n",
        "data_set_directory = \"/content/drive/My Drive/Group 77 - Pneumonia/pickle_augmented/\"\n",
        "\n",
        "for dataset in os.listdir(data_set_directory):\n",
        "  if dataset == \".ipynb_checkpoints\":\n",
        "    continue\n",
        "  dataset_path = data_set_directory + dataset\n",
        "  parameter_study(dataset_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted data set: aug-0_0_0.0_0_False.pickle\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Mounted data set: aug-0_0_0.0_0_False.pickle\n",
            "Train on 5331 samples, validate on 1570 samples\n",
            "Epoch 1/30\n",
            " 128/5331 [..............................] - ETA: 4:48 - loss: 36.5983 - acc: 0.3281 - precision: 0.0000e+00 - recall: 0.0000e+00WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.201282). Check your callbacks.\n",
            "5331/5331 [==============================] - 11s 2ms/sample - loss: 19.8440 - acc: 0.3461 - precision: 0.5714 - recall: 7.5033e-04 - val_loss: 8.7452 - val_acc: 0.2873 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/30\n",
            "5331/5331 [==============================] - 4s 751us/sample - loss: 5.2418 - acc: 0.3799 - precision: 0.4560 - recall: 0.0107 - val_loss: 2.9337 - val_acc: 0.4102 - val_precision: 0.6480 - val_recall: 0.1032\n",
            "Epoch 3/30\n",
            "5331/5331 [==============================] - 4s 747us/sample - loss: 2.0264 - acc: 0.6023 - precision: 0.6637 - recall: 0.4680 - val_loss: 1.3543 - val_acc: 0.7038 - val_precision: 0.7896 - val_recall: 0.5688\n",
            "Epoch 4/30\n",
            "5331/5331 [==============================] - 4s 745us/sample - loss: 1.1166 - acc: 0.6468 - precision: 0.6999 - recall: 0.5661 - val_loss: 0.8361 - val_acc: 0.7529 - val_precision: 0.7928 - val_recall: 0.6994\n",
            "Epoch 5/30\n",
            "5331/5331 [==============================] - 4s 751us/sample - loss: 0.7979 - acc: 0.6952 - precision: 0.7325 - recall: 0.6246 - val_loss: 0.6955 - val_acc: 0.7662 - val_precision: 0.8126 - val_recall: 0.6822\n",
            "Epoch 6/30\n",
            "5331/5331 [==============================] - 4s 749us/sample - loss: 0.6660 - acc: 0.7304 - precision: 0.7546 - recall: 0.6811 - val_loss: 0.6599 - val_acc: 0.7376 - val_precision: 0.7598 - val_recall: 0.7153\n",
            "Epoch 7/30\n",
            "5331/5331 [==============================] - 4s 747us/sample - loss: 0.6157 - acc: 0.7441 - precision: 0.7669 - recall: 0.6987 - val_loss: 0.5990 - val_acc: 0.7452 - val_precision: 0.7807 - val_recall: 0.7210\n",
            "Epoch 8/30\n",
            "5331/5331 [==============================] - 4s 755us/sample - loss: 0.5843 - acc: 0.7541 - precision: 0.7732 - recall: 0.7233 - val_loss: 0.5875 - val_acc: 0.7662 - val_precision: 0.7870 - val_recall: 0.7389\n",
            "Epoch 9/30\n",
            "5331/5331 [==============================] - 4s 750us/sample - loss: 0.5695 - acc: 0.7620 - precision: 0.7799 - recall: 0.7286 - val_loss: 0.5543 - val_acc: 0.7968 - val_precision: 0.8066 - val_recall: 0.7783\n",
            "Epoch 10/30\n",
            "5331/5331 [==============================] - 4s 748us/sample - loss: 0.5605 - acc: 0.7593 - precision: 0.7763 - recall: 0.7278 - val_loss: 0.5593 - val_acc: 0.7955 - val_precision: 0.8012 - val_recall: 0.7854\n",
            "Epoch 11/30\n",
            "5331/5331 [==============================] - 4s 754us/sample - loss: 0.5496 - acc: 0.7668 - precision: 0.7834 - recall: 0.7423 - val_loss: 0.5892 - val_acc: 0.7694 - val_precision: 0.7940 - val_recall: 0.7389\n",
            "Epoch 12/30\n",
            "5331/5331 [==============================] - 4s 753us/sample - loss: 0.5314 - acc: 0.7790 - precision: 0.7926 - recall: 0.7520 - val_loss: 0.5572 - val_acc: 0.7904 - val_precision: 0.7992 - val_recall: 0.7834\n",
            "Epoch 13/30\n",
            "5331/5331 [==============================] - 4s 753us/sample - loss: 0.5103 - acc: 0.7863 - precision: 0.8001 - recall: 0.7606 - val_loss: 0.5592 - val_acc: 0.7930 - val_precision: 0.8065 - val_recall: 0.7777\n",
            "Epoch 14/30\n",
            "5331/5331 [==============================] - 4s 751us/sample - loss: 0.4943 - acc: 0.7963 - precision: 0.8056 - recall: 0.7783 - val_loss: 0.5543 - val_acc: 0.7783 - val_precision: 0.7897 - val_recall: 0.7701\n",
            "Epoch 15/30\n",
            "5331/5331 [==============================] - 4s 750us/sample - loss: 0.4690 - acc: 0.8087 - precision: 0.8172 - recall: 0.7974 - val_loss: 0.5526 - val_acc: 0.7936 - val_precision: 0.8058 - val_recall: 0.7796\n",
            "Epoch 16/30\n",
            "5331/5331 [==============================] - 4s 747us/sample - loss: 0.4727 - acc: 0.8038 - precision: 0.8135 - recall: 0.7893 - val_loss: 0.5447 - val_acc: 0.7987 - val_precision: 0.8050 - val_recall: 0.7860\n",
            "Epoch 17/30\n",
            "5331/5331 [==============================] - 4s 742us/sample - loss: 0.5003 - acc: 0.8062 - precision: 0.8182 - recall: 0.7858 - val_loss: 0.5213 - val_acc: 0.8089 - val_precision: 0.8156 - val_recall: 0.7917\n",
            "Epoch 18/30\n",
            "5331/5331 [==============================] - 4s 746us/sample - loss: 0.4695 - acc: 0.8186 - precision: 0.8261 - recall: 0.8085 - val_loss: 0.5774 - val_acc: 0.7745 - val_precision: 0.7842 - val_recall: 0.7637\n",
            "Epoch 19/30\n",
            "5331/5331 [==============================] - 4s 750us/sample - loss: 0.4475 - acc: 0.8269 - precision: 0.8352 - recall: 0.8126 - val_loss: 0.5689 - val_acc: 0.7803 - val_precision: 0.7880 - val_recall: 0.7764\n",
            "Epoch 20/30\n",
            "5331/5331 [==============================] - 4s 752us/sample - loss: 0.4363 - acc: 0.8263 - precision: 0.8332 - recall: 0.8182 - val_loss: 0.5421 - val_acc: 0.8013 - val_precision: 0.8157 - val_recall: 0.7892\n",
            "Epoch 21/30\n",
            "5331/5331 [==============================] - 4s 751us/sample - loss: 0.4197 - acc: 0.8385 - precision: 0.8433 - recall: 0.8299 - val_loss: 0.5534 - val_acc: 0.7936 - val_precision: 0.7978 - val_recall: 0.7866\n",
            "Epoch 22/30\n",
            "5331/5331 [==============================] - 4s 748us/sample - loss: 0.4108 - acc: 0.8490 - precision: 0.8537 - recall: 0.8415 - val_loss: 0.5579 - val_acc: 0.8083 - val_precision: 0.8152 - val_recall: 0.8006\n",
            "Epoch 23/30\n",
            "5331/5331 [==============================] - 4s 755us/sample - loss: 0.4153 - acc: 0.8477 - precision: 0.8537 - recall: 0.8428 - val_loss: 0.5655 - val_acc: 0.8140 - val_precision: 0.8194 - val_recall: 0.8064\n",
            "Epoch 24/30\n",
            "5331/5331 [==============================] - 4s 751us/sample - loss: 0.3904 - acc: 0.8608 - precision: 0.8658 - recall: 0.8556 - val_loss: 0.5746 - val_acc: 0.7739 - val_precision: 0.7791 - val_recall: 0.7707\n",
            "Epoch 25/30\n",
            "5331/5331 [==============================] - 4s 749us/sample - loss: 0.3711 - acc: 0.8679 - precision: 0.8698 - recall: 0.8633 - val_loss: 0.6761 - val_acc: 0.8032 - val_precision: 0.8050 - val_recall: 0.8019\n",
            "Epoch 26/30\n",
            "5331/5331 [==============================] - 4s 745us/sample - loss: 0.3545 - acc: 0.8745 - precision: 0.8771 - recall: 0.8713 - val_loss: 0.6329 - val_acc: 0.7943 - val_precision: 0.7986 - val_recall: 0.7930\n",
            "Epoch 27/30\n",
            "5331/5331 [==============================] - 4s 751us/sample - loss: 0.3475 - acc: 0.8835 - precision: 0.8856 - recall: 0.8796 - val_loss: 0.6159 - val_acc: 0.7924 - val_precision: 0.7996 - val_recall: 0.7879\n",
            "Epoch 28/30\n",
            "5331/5331 [==============================] - 4s 751us/sample - loss: 0.3632 - acc: 0.8839 - precision: 0.8872 - recall: 0.8811 - val_loss: 0.6455 - val_acc: 0.7879 - val_precision: 0.7920 - val_recall: 0.7834\n",
            "Epoch 29/30\n",
            "5331/5331 [==============================] - 4s 749us/sample - loss: 0.3414 - acc: 0.8880 - precision: 0.8926 - recall: 0.8843 - val_loss: 0.7928 - val_acc: 0.7605 - val_precision: 0.7646 - val_recall: 0.7592\n",
            "Epoch 30/30\n",
            "5331/5331 [==============================] - 4s 747us/sample - loss: 0.3363 - acc: 0.8929 - precision: 0.8948 - recall: 0.8905 - val_loss: 0.6832 - val_acc: 0.7873 - val_precision: 0.7946 - val_recall: 0.7860\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}