{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Group_77-Pneumonia.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bennsamuel/Pneumonia-Project/blob/master/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1HJrduozTKM",
        "colab_type": "text"
      },
      "source": [
        "# Deletes log folder\n",
        "should not be used. Was implemented when cnn algorithm was not finshed to mingle around.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uukp28eezLbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# %cd /content/drive/My Drive/Group 77 - Pneumonia/logs\n",
        "# !rm -d -r *\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khtTZm2LqT9b",
        "colab_type": "text"
      },
      "source": [
        "# START HERE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gCSpATnMr5e",
        "colab_type": "code",
        "outputId": "20dcc201-1812-46af-8993-9284a824b825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# START HERE\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4AOCheJNu3U",
        "colab_type": "code",
        "outputId": "080e62da-3553-4f82-f804-acd3560591eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/drive/My Drive/Group 77 - Pneumonia/pickle/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_augmented.pickle  data.pickle  test_data.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peGASGqf1tHI",
        "colab_type": "code",
        "outputId": "0de098f1-d355-4d51-9350-0547ed5c0462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "IMG_SIZE = 224\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "#                0          1         2\n",
        "CATEGORIES = [\"NORMAL\",\"BACTERIA\", \"VIRUS\"]\n",
        "\n",
        "\n",
        "%cd /content/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G534nMYhAJEY",
        "colab_type": "text"
      },
      "source": [
        "## `DATA SET which should be used for training is defined here.`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wHYgnMIKEPlo",
        "colab_type": "code",
        "outputId": "207697fb-3ce4-4fd9-c59d-4dc8c3095581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#load dataset --> method baseline!\n",
        "import pickle\n",
        "\n",
        "# select which pickle folder\n",
        "data_set_folder_path = \"/content/drive/My Drive/Group 77 - Pneumonia/pickle_augmented/\"\n",
        "\n",
        "# HERE Define here which data set should be used for training\n",
        "\n",
        "data_set_path = \"/content/drive/My Drive/Group 77 - Pneumonia/pickle_augmented/augmented-0_0_0_0_0.pickle\"\n",
        "\n",
        "# extract name from dataset\n",
        "specific_data_set = data_set_path.split('/')[-1]\n",
        "\n",
        "data = pickle.load(open(data_set_path, \"rb\"))\n",
        "\n",
        "test_data = pickle.load(open(\"/content/drive/My Drive/Group 77 - Pneumonia/pickle/test_data.pickle\", \"rb\"))\n",
        "\n",
        "print(\"Mounted data set: {}\".format(specific_data_set))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted data set: augmented-0_0_0_0_0.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdZyLUR16qn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CZybEQwoEPlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# splitting data in training data and validation data \n",
        "# creating normalized SHUFFLED arrays\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for features, label in data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "    \n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# stratify preserves distribution of classes\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4,\n",
        "                                                  random_state=42, stratify=y)\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for features, label in test_data:\n",
        "    X_test.append(features)\n",
        "    y_test.append(label)\n",
        "    \n",
        "X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O9_iDu0sEPls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.asarray(X_train)\n",
        "y_train = np.asarray(y_train)\n",
        "\n",
        "X_val = np.asarray(X_val)\n",
        "y_val = np.asarray(y_val)\n",
        "\n",
        "X_test = np.asarray(X_test)\n",
        "y_test = np.asarray(y_test)\n",
        "\n",
        "X_train = X_train/255.0\n",
        "X_val = X_val/255.0\n",
        "X_test = X_test/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riG4HC1ZJcbt",
        "colab_type": "text"
      },
      "source": [
        "Create the plotting data for later. This is done at this point to have a the data before one hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl0p0M8RIdYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "train_plot_data = pd.DataFrame(y_train, columns=['CLASS'])\n",
        "train_plot_data['DATA SET'] = 'train'\n",
        "\n",
        "val_plot_data = pd.DataFrame(y_val, columns=['CLASS'])\n",
        "val_plot_data['DATA SET'] = 'val'\n",
        "\n",
        "to_merge = [train_plot_data, val_plot_data]\n",
        "merged_plot_data = pd.concat(to_merge)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i1TriNTImBb",
        "colab_type": "text"
      },
      "source": [
        "'one hot encode' classes\n",
        "\n",
        "before to_categorical: \n",
        "\n",
        "  [1, \n",
        "  2,\n",
        "  1, \n",
        "  0, \n",
        "  1, \n",
        "  2, \n",
        "  ...]\n",
        "\n",
        "after to_categorical:\n",
        "  [[0,1,0],\n",
        "   [0,0,1],\n",
        "   [0,1,0],\n",
        "   ...]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tGqdvi4Im3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_val = to_categorical(y_val, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hL_DPn8h4vo",
        "colab_type": "text"
      },
      "source": [
        "Possibility to export target data sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyXS7lAjhaiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pickle\n",
        "\n",
        "# %cd /content/drive/My Drive/Group 77 - Pneumonia/pickle\n",
        "\n",
        "# pickle_out = open(\"y_train.pickle\", \"wb\")\n",
        "# pickle.dump(y_train, pickle_out)\n",
        "# pickle_out.close()\n",
        "\n",
        "# pickle_out = open(\"y_val.pickle\", \"wb\")\n",
        "# pickle.dump(y_val, pickle_out)\n",
        "# pickle_out.close()\n",
        "\n",
        "# pickle_out = open(\"y_test.pickle\", \"wb\")\n",
        "# pickle.dump(y_test, pickle_out)\n",
        "# pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4aeHNCs4Pi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhZc6GMNurYi",
        "colab_type": "text"
      },
      "source": [
        "Defining layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1scT1xVPDyN2",
        "colab_type": "text"
      },
      "source": [
        "Code partially based on [stanford cs 231](http://cs231n.github.io/convolutional-networks/)\n",
        "\n",
        "**strides and dropout** \n",
        "\n",
        "Decided to use increased strides instead of maxpooling layer. Based on:\n",
        "https://www.kaggle.com/dansbecker/dropout-and-strides-for-larger-models\n",
        "\n",
        "and corresponding research paper:\n",
        "[\"Striving for Simplicity: The All Convolutional Net\"](https://academic.microsoft.com/paper/2963382180/citedby/search?q=Striving%20for%20Simplicity%3A%20The%20All%20Convolutional%20Net&qe=RId%253D2963382180&f=&orderBy=0)\n",
        "\n",
        "Dropout percentage (0.5) based on [this paper](https://academic.microsoft.com/paper/1904365287/reference/search?q=Improving%20neural%20networks%20by%20preventing%20co-adaptation%20of%20feature%20detectors&qe=Or(Id%253D2911964244%252CId%253D2108598243%252CId%253D2112796928%252CId%253D2100495367%252CId%253D2912934387%252CId%253D2116064496%252CId%253D2147768505%252CId%253D1993882792%252CId%253D4919037%252CId%253D1498436455%252CId%253D2053229256%252CId%253D2132424367%252CId%253D2184852195%252CId%253D1567512734%252CId%253D2150884987%252CId%253D2125725328%252CId%253D2465562739)&f=&orderBy=0)\n",
        "\n",
        "[another paper](http://jmlr.csail.mit.edu/papers/volume15/srivastava14a/srivastava14a.pdf) on dropout cited by google\n",
        "\n",
        "Why dropout is not used on convolutional layer:\n",
        "[link text](https://academic.microsoft.com/paper/2890166761/citedby/search?q=DropBlock%3A%20A%20regularization%20method%20for%20convolutional%20networks&qe=RId%253D2890166761&f=&orderBy=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Q-5ThfjpEPlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "import time\n",
        "\n",
        "NAME = \"{data_set} - {time}\".format(data_set = specific_data_set, time = time.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
        "\n",
        "tensorboard = TensorBoard(log_dir = \"/content/drive/My Drive/Group 77 - Pneumonia/logs/{}\".format(NAME))\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3),\n",
        "                 strides=2,\n",
        "                 activation='relu',\n",
        "                 input_shape=X_train.shape[1:]))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), strides=2, activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), strides=2, activation='relu'))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), strides=2, activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), strides=2, activation='relu'))\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), strides=2, activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# w/o regularization\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# with regularization\n",
        "model.add(Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.1)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.1)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Dense 3 softmax because we have 3 classes\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYCGbces_grt",
        "colab_type": "text"
      },
      "source": [
        "Fitting the model. If this is executed multiple times make sure that no addiotional layers were added by runnning the cell above. *THIS DOES NOT WORK. YOU HAVE TO RESTART THE RUNTIME* This can be checked with the model.layers variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgWk5UAyA2cJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Mounted data set: {}\".format(specific_data_set))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yoexBRn0yEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHuOkCRt_uO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precision = tf.keras.metrics.Precision()\n",
        "recall = tf.keras.metrics.Recall()\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", \n",
        "              optimizer=\"adam\", \n",
        "              metrics=[\"accuracy\", precision, recall])\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=30, validation_data=(X_val,y_val), callbacks = [tensorboard])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swb3Yu-LutGE",
        "colab_type": "text"
      },
      "source": [
        "fit model and define metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3uHqquJ6t8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill 401"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yRTOkoZmV_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izpEbXQomo6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# has to be run twice. no clue why\n",
        "\n",
        "%tensorboard --logdir \"/content/drive/My Drive/Group 77 - Pneumonia/logs\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHlccmssWKT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prevents tensorboard from creating new precision_1, precision_2 etc.\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0DfAb4lk-AA",
        "colab_type": "text"
      },
      "source": [
        "# data plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv_0G0IdDw5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.express as px\n",
        "fig = px.histogram(merged_plot_data, x='DATA SET', color=\"CLASS\")\n",
        "fig.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9Ua8H9bWXqh",
        "colab_type": "text"
      },
      "source": [
        "# Saving the model\n",
        "uncomment the code below to save the model (for it to be tested on the TEST set afterwards). This **must** be the final model. \n",
        "\n",
        "The model is then saved in colabs storage and has to be moved to your folder of destination manually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vtYfpZlWnxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.save(\"{name}.h5\".format(name=\"baseline\"))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}